# ğŸ§  LLM Decision Approximation

## Overview

This project investigates how the decision-making behavior of a **Large Language Model (LLM)** can be **approximated** within a **Markov Decision Process (MDP)**.  
The LLM receives states (e.g., traits and situational features) as input and produces action probabilities.  
A smaller, trainable model (e.g., MLP, Transformer) is used to approximate this behavior to enable efficient decision-making in simulation environments, such as agent-based systems.

---

## ğŸ“ Repository Structure

```
llm-decision-approximation/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw LLM outputs or prompt results
â”‚   â”œâ”€â”€ processed/           # Preprocessed train/test datasets
â”‚   â”œâ”€â”€ prompts/             # Prompt templates for data generation
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_setup_environment.ipynb     # Environment setup & package checks
â”‚   â”œâ”€â”€ 01_generate_datasets.ipynb     # Generate training/test data with LLM
â”‚   â”œâ”€â”€ 02_train_models.ipynb          # Train approximation models
â”‚   â”œâ”€â”€ 03_evaluate_models.ipynb       # Evaluate and compare architectures
â”‚   â”œâ”€â”€ 04_ablation_studies.ipynb      # Perform ablation and sensitivity studies
â”‚   â””â”€â”€ 05_visualization_results.ipynb # Visualize results and metrics
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_utils.py        # Data loading, preprocessing, splitting
â”‚   â”œâ”€â”€ model_utils.py       # Model definitions, training loops, losses
â”‚   â”œâ”€â”€ eval_utils.py        # Metrics, plotting, and evaluation
â”‚   â””â”€â”€ config.py            # Global paths and hyperparameters
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ saved_models/        # Trained model checkpoints
â”‚   â””â”€â”€ configs/             # Model configuration files
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ metrics/             # Evaluation metrics (CSV)
â”‚   â”œâ”€â”€ plots/               # Plots and visualizations
â”‚   â””â”€â”€ logs/                # Training logs and outputs
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/llm-decision-approximation.git
cd llm-decision-approximation
```

### 2ï¸âƒ£ Set up the environment
Using **conda**:
```bash
conda env create -f environment.yml
conda activate llm-decision-approximation
```

or using **pip**:
```bash
python -m venv venv
source venv/bin/activate      # (Linux/Mac)
venv\Scripts\activate         # (Windows)
pip install -r requirements.txt
```

---

## ğŸ§ª Notebooks Workflow

| Step | Notebook | Description |
|------|-----------|-------------|
| **0. Setup** | `00_setup_environment.ipynb` | Verify dependencies, GPU/CUDA availability, and setup |
| **1. Data Generation** | `01_generate_datasets.ipynb` | Generate train/test data via LLM (e.g., DeepSeek-R1, Llama) |
| **2. Training** | `02_train_models.ipynb` | Train multiple architectures (LogReg, MLP, Transformer) |
| **3. Evaluation** | `03_evaluate_models.ipynb` | Compute metrics such as KL, CE, ECE, and FQE |
| **4. Ablation** | `04_ablation_studies.ipynb` | Analyze influence of traits, inputs, and model design |
| **5. Visualization** | `05_visualization_results.ipynb` | Produce figures and plots for reports or publications |

---

## ğŸ§± Source Module Overview

| File | Purpose |
|------|----------|
| `data_utils.py` | Load, preprocess, and split datasets |
| `model_utils.py` | Define architectures and training loops |
| `eval_utils.py` | Compute metrics, visualize results |
| `config.py` | Centralized configuration and paths |
| `__init__.py` | Makes `src/` importable as a Python package |

---

## ğŸ“Š Key Evaluation Metrics

- **Cross-Entropy / KL-Divergence** â€“ Measures similarity between LLM and approximated policy  
- **Expected Calibration Error (ECE)** â€“ Evaluates probability calibration  
- **Fitted Q Evaluation (FQE)** â€“ Offline estimate of policy quality  
- **Ablation metrics** â€“ Effect of traits, context, or architecture variants

---

## ğŸ§  Research Objective

The repository supports a multi-phase research pipeline:

1. **Basic Project:** Develop and evaluate the foundational approximation architecture  
2. **Main Project:** Integrate the model into a Multi-Agent Simulation (e.g., Christmas market scenario)  
3. **Masterâ€™s Thesis:** Extend to a complex urban simulation validated with population data

---

## ğŸ§© Technologies Used

- **Python â‰¥ 3.10**
- **PyTorch**
- **Hugging Face Transformers**
- **Pandas, NumPy, scikit-learn**
- **Matplotlib, Seaborn**
- **Jupyter / JupyterLab**

---

## ğŸ“ˆ Usage Example

Launch Jupyter Lab:
```bash
jupyter lab notebooks/
```

Open `02_train_models.ipynb` and run:
```python
from src.model_utils import MLPPolicy, train_model
from src.data_utils import load_dataset
```

---

## ğŸ“„ License

MIT License Â© 2025 [Your Name]  
This project may be used and extended for research purposes.
